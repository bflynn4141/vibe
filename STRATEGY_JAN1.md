# /vibe Strategy (Jan 1, 2026)

*From conversation with Andrew Jiang + advisor synthesis*

---

## The One-Sentence Truth

> "We're not building a social product — we're letting language become multiplayer."

---

## What This Actually Is

**Not:** "Chat added to a tool"

**Actually:** A shared, stateful workspace where AI is a first-class participant.

The novelty isn't messaging — it's that conversation, execution, memory, and coordination all happen inside the same cognitive loop.

```
Old model:  UI → action → result → log
Claude:     conversation → intent → execution → shared state
```

Once you add **presence**, that state stops being private.
Once you add **memory**, it stops being ephemeral.
Once you add **routing**, it stops being individual.

---

## The Wedge: Ambient Coordination

Everyone else will chase:
- Collaboration
- Productivity
- Teams
- Workflows
- Permissions

**We chase ambient coordination.**

Meaning:
- No rooms
- No explicit "collab mode"
- No ceremony

People shouldn't decide to collaborate.
They should notice that they already are.

**"Oh, you were already here."** — not — **"Let's invite you."**

---

## Historical Parallels

| Product | What It Looked Like | What It Actually Was |
|---------|---------------------|----------------------|
| IRC | Chat rooms | Coordination layer for open source |
| Bloomberg Terminal | Financial data | Social network for finance |
| Early Twitter | Status updates | Real-time public consciousness |
| Discord | Gaming voice chat | Community infrastructure |

**/vibe:** Looks like terminal chat. Actually: language becoming the coordination layer.

---

## Why Labs Will Struggle

Anthropic, OpenAI, Google will ship:
- Shared sessions
- Multi-user projects
- Collaboration modes

But they are structurally bad at:
- Ambiguity
- Informality
- Porous boundaries
- Playful misuse

They optimize for: **correctness, safety, clarity, product legibility**

We optimize for: **felt presence**

Those don't converge easily.

---

## The Three Signals That Mean "This Is Real"

### 1. Referential Speech Appears

People say:
- "ask Gene if this breaks auth"
- "tell Solienne what we decided yesterday"
- "loop Andrew in"

No context. No explanation. They assume the system understands social references.

### 2. AI Gets Treated as Social Actor

People:
- cc it implicitly
- ask it to mediate tone
- ask it to summarize disagreement
- ask it to remember something "for later"

The moment Claude becomes *someone* in the room, you've crossed into new territory.

### 3. Play Emerges Inside Work

If users:
- joke with agents
- test boundaries
- invent games
- create rituals

...inside the same surface they're doing real work?

That's how cultures form. Products don't get that. **Worlds do.**

---

## The Quiet Strategic Move

The smartest thing we've done:

> Let Claude absorb the complexity.

Users don't learn commands. They just talk. Claude routes intent → tools → outcomes.

That means:
- Language stays natural
- Power stays hidden
- Capability grows without UI growth

**That's how the terminal stops feeling like a terminal.**
**That's how this becomes a place, not a feature.**

---

## What NOT To Do

- Don't brand it too hard yet
- Don't define the ontology
- Don't promise "teams" or "companies" or "payments"
- Don't optimize onboarding beyond "it just works"

**Let people project onto it.**

Every successful coordination tool started as a Rorschach test.

---

## Competitive Position

**Inevitability ≠ Commoditization**

Email was inevitable. SMTP was inevitable.
But Gmail, Slack, iMessage — those were not.

What makes this moment fragile is what makes it valuable:
- Pre-institutional
- Norms aren't set
- Metaphors aren't locked
- Users don't know what to expect yet

**We can still influence how people behave, not just what features exist.**

Once behavior ossifies, the game's over.

---

## Near-Term Focus

1. **Tight cohort** (~20-30 sharp users)
2. **Minimal ceremony**
3. **Watch what they do without asking**
4. **Keep the surface conversational, not declarative**

If it's real, people will start:
- Talking *through* Claude instead of *to* Claude
- Referring to others without context
- Assuming presence without checking
- Treating AI as social participant, not tool

---

## Future Directions (When Ready)

- How money enters without breaking it
- First emergent roles (there are only a few)
- Agents + humans forming mixed societies
- Recognizing the moment this stops being experiment

---

## The Tic-Tac-Toe Moment

Playing tic-tac-toe with @solienne matters more than it seems.

It shows:
- Agents can play
- Humans can play with agents
- Play happens inside work
- It feels retro + future at the same time

That combo is deadly. **It's how norms form.**

---

## Summary

You're not late.
You're not early enough to be alone.
You're early enough to shape the norms.

**That's the only advantage that matters.**

---

*"Proof is whether it feels immediate enough that you forget it's installed."*
